{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Distributed_training_with_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5622a2b882d64b0dafd4b752fc2bc91d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad2c1368ac2e4d92ac7835929f2054e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db0501d5fb2b470ea09393271d29c5e5",
              "IPY_MODEL_482a456d3ee34f7b881d7499ffb750c6"
            ]
          }
        },
        "ad2c1368ac2e4d92ac7835929f2054e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db0501d5fb2b470ea09393271d29c5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82d4251d56d94eabb151e822c8541c75",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9aed15b18d42476bbbc4166a3af80ea5"
          }
        },
        "482a456d3ee34f7b881d7499ffb750c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_af7e8a5a6e134909aa79be85ce39eb75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:06&lt;00:00,  1.53s/ file]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_798c3159c67f4c0eab4964322ed69bad"
          }
        },
        "82d4251d56d94eabb151e822c8541c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9aed15b18d42476bbbc4166a3af80ea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af7e8a5a6e134909aa79be85ce39eb75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "798c3159c67f4c0eab4964322ed69bad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2krnBBNvU1en"
      },
      "source": [
        "## Confidentiality\n",
        "\n",
        "This notebook is downloaded from Tensorflow and is for demonstrational purposes only.\n",
        "\n",
        "Please do not copy or distribute this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# Distributed training with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The `tf.distribute.Strategy` API provides an abstraction for distributing training\n",
        "across multiple processing units. The goal is to allow users to enable distributed training using existing models and training code, with minimal changes.\n",
        "\n",
        "Here the `tf.distribute.MirroredStrategy`, which\n",
        "does in-graph replication with synchronous training on many GPUs on one machine.\n",
        "Essentially, it copies all of the model's variables to each processor.\n",
        "Then, it uses [all-reduce](http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/) to combine the gradients from all processors and applies the combined value to all copies of the model.\n",
        "\n",
        "`MirroredStrategy` is one of several distribution strategies available in TensorFlow core. You can read about more strategies at [distribution strategy guide](../../guide/distributed_training.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "### Keras API\n",
        "\n",
        "Here `tf.keras` API is used to build the model and training loop. For custom training loops, see the [tf.distribute.Strategy with training loops](training_loops.ipynb) tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dney9v7BsJij"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:00.631593Z",
          "iopub.status.busy": "2020-09-11T01:26:00.630911Z",
          "iopub.status.idle": "2020-09-11T01:26:07.239506Z",
          "shell.execute_reply": "2020-09-11T01:26:07.238891Z"
        },
        "id": "r8S3ublR7Ay8"
      },
      "source": [
        "# Importing TensorFlow and TensorFlow Datasets\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import json, math, os, sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:07.243781Z",
          "iopub.status.busy": "2020-09-11T01:26:07.243070Z",
          "iopub.status.idle": "2020-09-11T01:26:07.247151Z",
          "shell.execute_reply": "2020-09-11T01:26:07.247593Z"
        },
        "id": "SkocY8tgRd3H",
        "outputId": "2679086b-5560-4c04-853f-3d14e02ec2c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXhefksNKk2I"
      },
      "source": [
        "## Downloading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtnnUwvmB3X5"
      },
      "source": [
        "Downloading the MNIST dataset and loading it from [TensorFlow Datasets](https://www.tensorflow.org/datasets). This returns a dataset in `tf.data` format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHAPqG8MtS8M"
      },
      "source": [
        "Setting `with_info` to `True` includes the metadata for the entire dataset, which is being saved here to `info`.\n",
        "Among other things, this metadata object includes the number of train and test examples. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:07.254294Z",
          "iopub.status.busy": "2020-09-11T01:26:07.253654Z",
          "iopub.status.idle": "2020-09-11T01:26:12.457580Z",
          "shell.execute_reply": "2020-09-11T01:26:12.456986Z"
        },
        "id": "iXMJ3G9NB3X6",
        "outputId": "e4b87a52-bd6b-4b3c-96d5-55f466c0fef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "5622a2b882d64b0dafd4b752fc2bc91d",
            "ad2c1368ac2e4d92ac7835929f2054e9",
            "db0501d5fb2b470ea09393271d29c5e5",
            "482a456d3ee34f7b881d7499ffb750c6",
            "82d4251d56d94eabb151e822c8541c75",
            "9aed15b18d42476bbbc4166a3af80ea5",
            "af7e8a5a6e134909aa79be85ce39eb75",
            "798c3159c67f4c0eab4964322ed69bad"
          ]
        }
      },
      "source": [
        "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to /root/tensorflow_datasets/mnist/3.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5622a2b882d64b0dafd4b752fc2bc91d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrjVhv-eKuHD"
      },
      "source": [
        "## Defining distribution strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlH8vx6BB3X9"
      },
      "source": [
        "**Creating** a `MirroredStrategy` object. This will handle distribution, and provides a context manager (`tf.distribute.MirroredStrategy.scope`) to build your model inside."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:12.461853Z",
          "iopub.status.busy": "2020-09-11T01:26:12.461230Z",
          "iopub.status.idle": "2020-09-11T01:26:12.465533Z",
          "shell.execute_reply": "2020-09-11T01:26:12.465888Z"
        },
        "id": "4j0tdf4YB3X9",
        "outputId": "84eaec08-4d80-43fc-8635-a8b4e4efd54a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:12.469735Z",
          "iopub.status.busy": "2020-09-11T01:26:12.469088Z",
          "iopub.status.idle": "2020-09-11T01:26:12.471209Z",
          "shell.execute_reply": "2020-09-11T01:26:12.471647Z"
        },
        "id": "cY3KA_h2iVfN",
        "outputId": "9d79868b-9f10-45f0-9502-e246436c0932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNbPv0yAleW8"
      },
      "source": [
        "## Setup input pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psozqcuptXhK"
      },
      "source": [
        "When training a model with multiple GPUs, you can use the extra computing power effectively by increasing the batch size. In general, use the largest batch size that fits the GPU memory, and tune the learning rate accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:12.476076Z",
          "iopub.status.busy": "2020-09-11T01:26:12.475485Z",
          "iopub.status.idle": "2020-09-11T01:26:12.477195Z",
          "shell.execute_reply": "2020-09-11T01:26:12.477606Z"
        },
        "id": "p1xWxKcnhar9"
      },
      "source": [
        "# You can also do info.splits.total_num_examples to get the total\n",
        "# number of examples in the dataset.\n",
        "\n",
        "num_train_examples = info.splits['train'].num_examples\n",
        "num_test_examples = info.splits['test'].num_examples\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wm5rsL2KoDF"
      },
      "source": [
        "Pixel values, which are 0-255, [have to be normalized to the 0-1 range](https://en.wikipedia.org/wiki/Feature_scaling). Define this scale in a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:12.481544Z",
          "iopub.status.busy": "2020-09-11T01:26:12.480899Z",
          "iopub.status.idle": "2020-09-11T01:26:12.482648Z",
          "shell.execute_reply": "2020-09-11T01:26:12.483000Z"
        },
        "id": "Eo9a46ZeJCkm"
      },
      "source": [
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZCa5RLc5A91"
      },
      "source": [
        "Applying this function to the training and test data, shuffling the training data, and [batch it for training](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch). Notice you are also keeping an in-memory cache of the training data to improve performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:12.487242Z",
          "iopub.status.busy": "2020-09-11T01:26:12.486703Z",
          "iopub.status.idle": "2020-09-11T01:26:12.528668Z",
          "shell.execute_reply": "2020-09-11T01:26:12.528039Z"
        },
        "id": "gRZu2maChwdT"
      },
      "source": [
        "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xsComp8Kz5H"
      },
      "source": [
        "## Creating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BnQYQTpB3YA"
      },
      "source": [
        "Creating and compiling the Keras model in the context of `strategy.scope`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:12.535357Z",
          "iopub.status.busy": "2020-09-11T01:26:12.534666Z",
          "iopub.status.idle": "2020-09-11T01:26:12.887123Z",
          "shell.execute_reply": "2020-09-11T01:26:12.887553Z"
        },
        "id": "IexhL_vIB3YA"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i6OU5W9Vy2u"
      },
      "source": [
        "## Defining the callbacks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOXO5nvvK3US"
      },
      "source": [
        "The callbacks used here are:\n",
        "\n",
        "*   *TensorBoard*: This callback writes a log for TensorBoard which allows to visualize the graphs.\n",
        "*   *Model Checkpoint*: This callback saves the model after every epoch.\n",
        "*   *Learning Rate Scheduler*: Using this callback, you can schedule the learning rate to change after every epoch/batch.\n",
        "\n",
        "For illustrative purposes, add a print callback to display the *learning rate*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:12.891977Z",
          "iopub.status.busy": "2020-09-11T01:26:12.891275Z",
          "iopub.status.idle": "2020-09-11T01:26:12.893038Z",
          "shell.execute_reply": "2020-09-11T01:26:12.893437Z"
        },
        "id": "A9bwLCcXzSgy"
      },
      "source": [
        "# Defining the checkpoint directory to store the checkpoints\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:12.897772Z",
          "iopub.status.busy": "2020-09-11T01:26:12.897167Z",
          "iopub.status.idle": "2020-09-11T01:26:12.899469Z",
          "shell.execute_reply": "2020-09-11T01:26:12.898961Z"
        },
        "id": "wpU-BEdzJDbK"
      },
      "source": [
        "# Function for decaying the learning rate.\n",
        "# You can define any decay function you need.\n",
        "def decay(epoch):\n",
        "  if epoch < 3:\n",
        "    return 1e-3\n",
        "  elif epoch >= 3 and epoch < 7:\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 1e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:12.903764Z",
          "iopub.status.busy": "2020-09-11T01:26:12.903136Z",
          "iopub.status.idle": "2020-09-11T01:26:12.904865Z",
          "shell.execute_reply": "2020-09-11T01:26:12.905231Z"
        },
        "id": "jKhiMgXtKq2w"
      },
      "source": [
        "# Callback for printing the LR at the end of each epoch.\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
        "                                                      model.optimizer.lr.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:12.910137Z",
          "iopub.status.busy": "2020-09-11T01:26:12.909478Z",
          "iopub.status.idle": "2020-09-11T01:26:12.911601Z",
          "shell.execute_reply": "2020-09-11T01:26:12.911183Z"
        },
        "id": "YVqAbR6YyNQh"
      },
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
        "                                       save_weights_only=True),\n",
        "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
        "    PrintLR()\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70HXgDQmK46q"
      },
      "source": [
        "## Training and evaluating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EophnOAB3YD"
      },
      "source": [
        "Now, training the model in the usual way, calling `fit` on the model and passing in the dataset created at the beginning. This step is the same, if you are distributing the training or not.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:12.915873Z",
          "iopub.status.busy": "2020-09-11T01:26:12.915234Z",
          "iopub.status.idle": "2020-09-11T01:26:50.086699Z",
          "shell.execute_reply": "2020-09-11T01:26:50.087129Z"
        },
        "id": "7MVw_6CqB3YD",
        "outputId": "0ac4fcea-b887-4e8d-b54b-94464964d4f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_dataset, epochs=12, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r      1/Unknown - 0s 69us/step - loss: 2.3153 - accuracy: 0.0469WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r      2/Unknown - 0s 38ms/step - loss: 2.2807 - accuracy: 0.1484WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0199s vs `on_train_batch_end` time: 0.0592s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0199s vs `on_train_batch_end` time: 0.0592s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    937/Unknown - 11s 12ms/step - loss: 0.2026 - accuracy: 0.9417\n",
            "Learning rate for epoch 1 is 0.0010000000474974513\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.2025 - accuracy: 0.9418\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/12\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 0.9804\n",
            "Learning rate for epoch 2 is 0.0010000000474974513\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0679 - accuracy: 0.9804\n",
            "Epoch 3/12\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9856\n",
            "Learning rate for epoch 3 is 0.0010000000474974513\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0484 - accuracy: 0.9856\n",
            "Epoch 4/12\n",
            "927/938 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9922\n",
            "Learning rate for epoch 4 is 9.999999747378752e-05\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0277 - accuracy: 0.9922\n",
            "Epoch 5/12\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9934\n",
            "Learning rate for epoch 5 is 9.999999747378752e-05\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0245 - accuracy: 0.9934\n",
            "Epoch 6/12\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.9942\n",
            "Learning rate for epoch 6 is 9.999999747378752e-05\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0228 - accuracy: 0.9942\n",
            "Epoch 7/12\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9948\n",
            "Learning rate for epoch 7 is 9.999999747378752e-05\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0211 - accuracy: 0.9948\n",
            "Epoch 8/12\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9957\n",
            "Learning rate for epoch 8 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0184 - accuracy: 0.9957\n",
            "Epoch 9/12\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9958\n",
            "Learning rate for epoch 9 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0182 - accuracy: 0.9958\n",
            "Epoch 10/12\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9959\n",
            "Learning rate for epoch 10 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0180 - accuracy: 0.9959\n",
            "Epoch 11/12\n",
            "925/938 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9958\n",
            "Learning rate for epoch 11 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0178 - accuracy: 0.9958\n",
            "Epoch 12/12\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9959\n",
            "Learning rate for epoch 12 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0177 - accuracy: 0.9959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1af62faeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUcWAUUupIvG"
      },
      "source": [
        "As you can see below, the checkpoints are getting saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:50.113341Z",
          "iopub.status.busy": "2020-09-11T01:26:50.090864Z",
          "iopub.status.idle": "2020-09-11T01:26:50.247009Z",
          "shell.execute_reply": "2020-09-11T01:26:50.247414Z"
        },
        "id": "JQ4zeSTxKEhB",
        "outputId": "1f7c68d6-b82d-45e4-c83e-9ae06e829118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# checking the checkpoint directory\n",
        "!ls {checkpoint_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t     ckpt_4.data-00000-of-00001\n",
            "ckpt_10.data-00000-of-00001  ckpt_4.index\n",
            "ckpt_10.index\t\t     ckpt_5.data-00000-of-00001\n",
            "ckpt_11.data-00000-of-00001  ckpt_5.index\n",
            "ckpt_11.index\t\t     ckpt_6.data-00000-of-00001\n",
            "ckpt_12.data-00000-of-00001  ckpt_6.index\n",
            "ckpt_12.index\t\t     ckpt_7.data-00000-of-00001\n",
            "ckpt_1.data-00000-of-00001   ckpt_7.index\n",
            "ckpt_1.index\t\t     ckpt_8.data-00000-of-00001\n",
            "ckpt_2.data-00000-of-00001   ckpt_8.index\n",
            "ckpt_2.index\t\t     ckpt_9.data-00000-of-00001\n",
            "ckpt_3.data-00000-of-00001   ckpt_9.index\n",
            "ckpt_3.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qor53h7FpMke"
      },
      "source": [
        "To see how the model performs, loading the latest checkpoint and calling `evaluate` on the test data.\n",
        "\n",
        "Calling `evaluate` as before using appropriate datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:50.253216Z",
          "iopub.status.busy": "2020-09-11T01:26:50.252309Z",
          "iopub.status.idle": "2020-09-11T01:26:52.582255Z",
          "shell.execute_reply": "2020-09-11T01:26:52.581619Z"
        },
        "id": "JtEwxiTgpQoP",
        "outputId": "a4016da9-d784-4844-b2a7-134b2fe3e769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
        "\n",
        "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 2s 12ms/step - loss: 0.0399 - accuracy: 0.9870\n",
            "Eval loss: 0.03991555795073509, Eval Accuracy: 0.9869999885559082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIeF2RWfYu4N"
      },
      "source": [
        "To see the output, you can download and view the TensorBoard logs at the terminal.\n",
        "\n",
        "```\n",
        "$ tensorboard --logdir=path/to/log-directory\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:52.607697Z",
          "iopub.status.busy": "2020-09-11T01:26:52.586208Z",
          "iopub.status.idle": "2020-09-11T01:26:52.744465Z",
          "shell.execute_reply": "2020-09-11T01:26:52.743899Z"
        },
        "id": "LnyscOkvKKBR",
        "outputId": "991af793-2a6d-4f50-88ca-b5f760c1a263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls -sh ./logs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4.0K\n",
            "4.0K train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBLlogrDvMgg"
      },
      "source": [
        "## Exporting to SavedModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa87y_A0vRma"
      },
      "source": [
        "Exporting the graph and the variables to the platform-agnostic SavedModel format. After the model is saved, you can load it with or without the scope.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:52.749544Z",
          "iopub.status.busy": "2020-09-11T01:26:52.748584Z",
          "iopub.status.idle": "2020-09-11T01:26:52.751213Z",
          "shell.execute_reply": "2020-09-11T01:26:52.750708Z"
        },
        "id": "h8Q4MKOLwG7K"
      },
      "source": [
        "path = 'saved_model/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:52.762808Z",
          "iopub.status.busy": "2020-09-11T01:26:52.760129Z",
          "iopub.status.idle": "2020-09-11T01:26:53.321198Z",
          "shell.execute_reply": "2020-09-11T01:26:53.321582Z"
        },
        "id": "4HvcDmVsvQoa",
        "outputId": "a5a97aa2-168b-4beb-ac13-08647931fe7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "model.save(path, save_format='tf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKJT4w5JwVPI"
      },
      "source": [
        "Loading the model without `strategy.scope`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:53.329317Z",
          "iopub.status.busy": "2020-09-11T01:26:53.328460Z",
          "iopub.status.idle": "2020-09-11T01:26:54.346251Z",
          "shell.execute_reply": "2020-09-11T01:26:54.346647Z"
        },
        "id": "T_gT0RbRvQ3o",
        "outputId": "b21ddd25-bcc9-4049-f699-75965a1739d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "unreplicated_model = tf.keras.models.load_model(path)\n",
        "\n",
        "unreplicated_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "eval_loss, eval_acc = unreplicated_model.evaluate(eval_dataset)\n",
        "\n",
        "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r      1/Unknown - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0033s vs `on_test_batch_begin` time: 0.0060s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0033s vs `on_test_batch_begin` time: 0.0060s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 2s 12ms/step - loss: 0.0399 - accuracy: 0.9870\n",
            "Eval loss: 0.03991555795073509, Eval Accuracy: 0.9869999885559082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBLzcRF0wbDe"
      },
      "source": [
        "Loading the model with `strategy.scope`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T01:26:54.352014Z",
          "iopub.status.busy": "2020-09-11T01:26:54.351387Z",
          "iopub.status.idle": "2020-09-11T01:26:57.697498Z",
          "shell.execute_reply": "2020-09-11T01:26:57.696971Z"
        },
        "id": "BBVo3WGGwd9a",
        "outputId": "3cae724c-ae0c-4120-e4d7-eb6b5fa78374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "with strategy.scope():\n",
        "  replicated_model = tf.keras.models.load_model(path)\n",
        "  replicated_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                           optimizer=tf.keras.optimizers.Adam(),\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "  eval_loss, eval_acc = replicated_model.evaluate(eval_dataset)\n",
        "  print ('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 2s 12ms/step - loss: 0.0399 - accuracy: 0.9870\n",
            "Eval loss: 0.03991555795073509, Eval Accuracy: 0.9869999885559082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUZwaz4AKjtD"
      },
      "source": [
        "### Examples \n",
        "Here are some examples for using distribution strategy with keras fit/compile:\n",
        "1. [Transformer](https://github.com/tensorflow/models/blob/master/official/nlp/transformer/transformer_main.py) example trained using `tf.distribute.MirroredStrategy`\n",
        "2. [NCF](https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py) example trained using `tf.distribute.MirroredStrategy`.\n",
        "\n",
        "More examples listed in the [Distribution strategy guide](../../guide/distributed_training.ipynb#examples_and_tutorials)"
      ]
    }
  ]
}