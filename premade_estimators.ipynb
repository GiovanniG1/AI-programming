{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "premade_estimators.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0-fL-LGwANI"
      },
      "source": [
        "## Confidentiality\n",
        "\n",
        "This notebook is downloaded from Tensorflow and is for demonstrational purposes only.\n",
        "\n",
        "Please do not copy or distribute this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1yCdGFW4j_F"
      },
      "source": [
        "# Premade Estimators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4YZ_ievcY7p"
      },
      "source": [
        "Here's shown how to solve a classification problem in TensorFlow using Estimators. An Estimator is TensorFlow's high-level representation of a complete model, and it has been designed for easy scaling and asynchronous training. For more details see\n",
        "[Estimators](https://www.tensorflow.org/guide/estimator).\n",
        "\n",
        "Note that in TensorFlow 2.0, the [Keras API](https://www.tensorflow.org/guide/keras) can accomplish many of these same tasks, and is believed to be an easier API to learn. For more information about the available high level APIs in TensorFlow 2.0, see [Standardizing on Keras](https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IFct0yedsTy"
      },
      "source": [
        "## First things first\n",
        "\n",
        "First importing TensorFlow and a number of libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPo5bQwndr9P"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5w4m5gncnGh"
      },
      "source": [
        "## The data set\n",
        "\n",
        "The sample program in this document builds and tests a model that\n",
        "classifies Iris flowers into three different species based on the size of their\n",
        "[sepals](https://en.wikipedia.org/wiki/Sepal) and\n",
        "[petals](https://en.wikipedia.org/wiki/Petal).\n",
        "\n",
        "\n",
        "A model is trained using this data set. The dataset contains four features and one\n",
        "[label](https://developers.google.com/machine-learning/glossary/#label).\n",
        "The four features identify the following botanical characteristics of\n",
        "individual flowers:\n",
        "\n",
        "* sepal length\n",
        "* sepal width\n",
        "* petal length\n",
        "* petal width\n",
        "\n",
        "Based on this information, you can define a few helpful constants for parsing the data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSyrXp_He_UE"
      },
      "source": [
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6mTfIQzfC9w"
      },
      "source": [
        "Next, downloading and parsing the data set using Keras and Pandas. Note that you keep distinct datasets for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PumyCN8VdGGc",
        "outputId": "ab6eca3d-9342-484d-c490-5f97d2961601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "train_path = tf.keras.utils.get_file(\n",
        "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
            "\r8192/2194 [================================================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
            "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHFxNLszhQjz"
      },
      "source": [
        "You can inspect your data to see that you have four float feature columns and one int32 label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOJt-ML4hAwI",
        "outputId": "604081ed-69bc-4f64-f168-62c1b103a19d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
              "0          6.4         2.8          5.6         2.2        2\n",
              "1          5.0         2.3          3.3         1.0        1\n",
              "2          4.9         2.5          4.5         1.7        2\n",
              "3          4.9         3.1          1.5         0.1        0\n",
              "4          5.7         3.8          1.7         0.3        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQJEYfVvfznP"
      },
      "source": [
        "For each of the datasets, splitting out the labels, which the model will be trained to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM0wz2TueuA6",
        "outputId": "ad39324c-0cbf-43f0-b06a-3b7b3359f81d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_y = train.pop('Species')\n",
        "test_y = test.pop('Species')\n",
        "\n",
        "# The label column has now been removed from the features.\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
              "0          6.4         2.8          5.6         2.2\n",
              "1          5.0         2.3          3.3         1.0\n",
              "2          4.9         2.5          4.5         1.7\n",
              "3          4.9         3.1          1.5         0.1\n",
              "4          5.7         3.8          1.7         0.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZx1L_1Vcmxv"
      },
      "source": [
        "## Overview of programming with Estimators\n",
        "\n",
        "Now that you have the data set up, you can define a model using a TensorFlow Estimator. An Estimator is any class derived from `tf.estimator.Estimator`. TensorFlow\n",
        "provides a collection of\n",
        "`tf.estimator`\n",
        "(for example, `LinearRegressor`) to implement common ML algorithms. Beyond\n",
        "those, you can write your own\n",
        "[custom Estimators](https://www.tensorflow.org/guide/custom_estimators).\n",
        "It's recommended using pre-made Estimators first.\n",
        "\n",
        "To write a TensorFlow program based on pre-made Estimators,perform the\n",
        "following tasks:\n",
        "\n",
        "* Create one or more input functions.\n",
        "* Define the model's feature columns.\n",
        "* Instantiate an Estimator, specifying the feature columns and various\n",
        "  hyperparameters.\n",
        "* Call one or more methods on the Estimator object, passing the appropriate\n",
        "  input function as the source of the data.\n",
        "\n",
        "Let's see how those tasks are implemented for this classification dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OcguDfBcmmg"
      },
      "source": [
        "## Creating input functions\n",
        "\n",
        "You must create input functions to supply data for training,\n",
        "evaluating, and prediction.\n",
        "\n",
        "An **input function** is a function that returns a `tf.data.Dataset` object\n",
        "which outputs the following two-element tuple:\n",
        "\n",
        "* [`features`](https://developers.google.com/machine-learning/glossary/#feature) - A Python dictionary in which:\n",
        "    * Each key is the name of a feature.\n",
        "    * Each value is an array containing all of that feature's values.\n",
        "* `label` - An array containing the values of the\n",
        "  [label](https://developers.google.com/machine-learning/glossary/#label) for\n",
        "  every example.\n",
        "\n",
        "Here's a simple\n",
        "implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzr5vRr5caGF"
      },
      "source": [
        "def input_evaluation_set():\n",
        "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
        "                'SepalWidth':  np.array([2.8, 2.3]),\n",
        "                'PetalLength': np.array([5.6, 3.3]),\n",
        "                'PetalWidth':  np.array([2.2, 1.0])}\n",
        "    labels = np.array([2, 1])\n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpXvGjfnjHgY"
      },
      "source": [
        "Your input function may generate the `features` dictionary and `label` list any\n",
        "way you like. However, it's recommended using TensorFlow's [Dataset API](https://www.tensorflow.org/guide/datasets), which can\n",
        "parse all sorts of data.\n",
        "\n",
        "The Dataset API can handle a lot of common cases for you. For example,\n",
        "using the Dataset API, you can easily read in records from a large collection\n",
        "of files in parallel and join them into a single stream.\n",
        "\n",
        "Loading the data with\n",
        "[pandas](https://pandas.pydata.org/), and build an input pipeline from this\n",
        "in-memory data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T20u1anCi8NP"
      },
      "source": [
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    \"\"\"An input function for training or evaluating\"\"\"\n",
        "    # Converting the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffling and repeating if you are in training mode.\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "    \n",
        "    return dataset.batch(batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIwcFT4MlZEi"
      },
      "source": [
        "## Defining the feature columns\n",
        "\n",
        "A [**feature column**](https://developers.google.com/machine-learning/glossary/#feature_columns)\n",
        "is an object describing how the model should use raw input data from the\n",
        "features dictionary. When building an Estimator model, you pass it a list of\n",
        "feature columns that describes each of the features you want the model to use.\n",
        "The `tf.feature_column` module provides many options for representing data\n",
        "to the model.\n",
        "\n",
        "For this dataset, the 4 raw features are numeric values, so you can build a list of\n",
        "feature columns to tell the Estimator model to represent each of the four\n",
        "features as 32-bit floating-point values. Therefore, the code to create the\n",
        "feature column is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTTriO8FlSML"
      },
      "source": [
        "# Feature columns describing how to use the input.\n",
        "my_feature_columns = []\n",
        "for key in train.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpKkhMoZljco"
      },
      "source": [
        "Feature columns can be far more sophisticated than this offcourse.  You can read more about Feature Columns in [this guide](https://www.tensorflow.org/guide/feature_columns).\n",
        "\n",
        "Now that there's an description of how you want the model to represent the raw\n",
        "features, you can build the estimator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuE59XHEl22K"
      },
      "source": [
        "## Instantiate an estimator\n",
        "\n",
        "This dataset is a classic classification problem. Fortunately, TensorFlow\n",
        "provides several pre-made classifier Estimators, including:\n",
        "\n",
        "* `tf.estimator.DNNClassifier` for deep models that perform multi-class\n",
        "  classification.\n",
        "* `tf.estimator.DNNLinearCombinedClassifier` for wide & deep models.\n",
        "* `tf.estimator.LinearClassifier` for classifiers based on linear models.\n",
        "\n",
        "For this classification problem, `tf.estimator.DNNClassifier` seems the best choice.\n",
        "Here's how you instantiated this Estimator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnf4o2V5lcPn",
        "outputId": "2ad79131-e762-413b-cced-e2806e5686d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# Building a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    # Two hidden layers of 30 and 10 nodes respectively.\n",
        "    hidden_units=[30, 10],\n",
        "    # The model must choose between 3 classes.\n",
        "    n_classes=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpev61z9uz\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpev61z9uz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzzt5nUpmEe3"
      },
      "source": [
        "## Training, Evaluating, and Predicting\n",
        "\n",
        "Now that there's an Estimator object, you can call methods to do the following:\n",
        "\n",
        "* Train the model.\n",
        "* Evaluate the trained model.\n",
        "* Use the trained model to make predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnihuLdWmE75"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "Training the model by calling the Estimator's `train` method as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jW08YtPl1iS",
        "outputId": "338c70ab-b5a9-4c64-db5a-e5247f30b411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training the Model.\n",
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
        "    steps=5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:83: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpev61z9uz/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 1.0681714, step = 0\n",
            "INFO:tensorflow:global_step/sec: 530.878\n",
            "INFO:tensorflow:loss = 0.8765314, step = 100 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 637.475\n",
            "INFO:tensorflow:loss = 0.83788186, step = 200 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 656.138\n",
            "INFO:tensorflow:loss = 0.81540585, step = 300 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.711\n",
            "INFO:tensorflow:loss = 0.794719, step = 400 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.261\n",
            "INFO:tensorflow:loss = 0.7776144, step = 500 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.219\n",
            "INFO:tensorflow:loss = 0.7614954, step = 600 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 657.114\n",
            "INFO:tensorflow:loss = 0.75222105, step = 700 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.992\n",
            "INFO:tensorflow:loss = 0.73265755, step = 800 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 662.217\n",
            "INFO:tensorflow:loss = 0.7183071, step = 900 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 581.808\n",
            "INFO:tensorflow:loss = 0.71194905, step = 1000 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 662.841\n",
            "INFO:tensorflow:loss = 0.6934444, step = 1100 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.013\n",
            "INFO:tensorflow:loss = 0.68561316, step = 1200 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.824\n",
            "INFO:tensorflow:loss = 0.67533684, step = 1300 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.064\n",
            "INFO:tensorflow:loss = 0.6610606, step = 1400 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.038\n",
            "INFO:tensorflow:loss = 0.64779276, step = 1500 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 633.917\n",
            "INFO:tensorflow:loss = 0.6335805, step = 1600 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.402\n",
            "INFO:tensorflow:loss = 0.63471425, step = 1700 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.985\n",
            "INFO:tensorflow:loss = 0.6135538, step = 1800 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.692\n",
            "INFO:tensorflow:loss = 0.6022366, step = 1900 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 684.227\n",
            "INFO:tensorflow:loss = 0.6000565, step = 2000 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.649\n",
            "INFO:tensorflow:loss = 0.5814228, step = 2100 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 680.137\n",
            "INFO:tensorflow:loss = 0.56513935, step = 2200 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.336\n",
            "INFO:tensorflow:loss = 0.5694465, step = 2300 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.235\n",
            "INFO:tensorflow:loss = 0.5517621, step = 2400 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.61\n",
            "INFO:tensorflow:loss = 0.54736984, step = 2500 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.486\n",
            "INFO:tensorflow:loss = 0.54074895, step = 2600 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.072\n",
            "INFO:tensorflow:loss = 0.53454554, step = 2700 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 586.416\n",
            "INFO:tensorflow:loss = 0.5257511, step = 2800 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.7\n",
            "INFO:tensorflow:loss = 0.51474327, step = 2900 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 601.662\n",
            "INFO:tensorflow:loss = 0.5035064, step = 3000 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 590.51\n",
            "INFO:tensorflow:loss = 0.49409783, step = 3100 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 592.123\n",
            "INFO:tensorflow:loss = 0.49764675, step = 3200 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.546\n",
            "INFO:tensorflow:loss = 0.48781115, step = 3300 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 587.035\n",
            "INFO:tensorflow:loss = 0.4816908, step = 3400 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.667\n",
            "INFO:tensorflow:loss = 0.47214198, step = 3500 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 583.816\n",
            "INFO:tensorflow:loss = 0.46377063, step = 3600 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.304\n",
            "INFO:tensorflow:loss = 0.45024842, step = 3700 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 592.752\n",
            "INFO:tensorflow:loss = 0.45147634, step = 3800 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.762\n",
            "INFO:tensorflow:loss = 0.44127798, step = 3900 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.235\n",
            "INFO:tensorflow:loss = 0.44464594, step = 4000 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.173\n",
            "INFO:tensorflow:loss = 0.4421075, step = 4100 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 579.031\n",
            "INFO:tensorflow:loss = 0.4290694, step = 4200 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 595.679\n",
            "INFO:tensorflow:loss = 0.41802534, step = 4300 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 565.089\n",
            "INFO:tensorflow:loss = 0.42110932, step = 4400 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 577.723\n",
            "INFO:tensorflow:loss = 0.4051935, step = 4500 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.548\n",
            "INFO:tensorflow:loss = 0.40109372, step = 4600 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 580.953\n",
            "INFO:tensorflow:loss = 0.3981571, step = 4700 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.168\n",
            "INFO:tensorflow:loss = 0.39258364, step = 4800 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 561.731\n",
            "INFO:tensorflow:loss = 0.39121902, step = 4900 (0.177 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpev61z9uz/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:Loss for final step: 0.38592353.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7fbde5df3198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybiTFDmlmes8"
      },
      "source": [
        "Note that you wrap up your `input_fn` call in a\n",
        "[`lambda`](https://docs.python.org/3/tutorial/controlflow.html)\n",
        "to capture the arguments while providing an input function that takes no\n",
        "arguments, as expected by the Estimator. The `steps` argument tells the method\n",
        "to stop training after a number of training steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNvJLH8hmsdf"
      },
      "source": [
        "### Evaluating the trained model\n",
        "\n",
        "Now that the model has been trained, you can get some statistics on its\n",
        "performance. The following code evaluates the accuracy of the trained\n",
        "model on the test data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A169XuO4mKxF",
        "outputId": "1b4e7323-2575-4d32-d29c-c6c0615c39d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
        "\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-10-10T18:23:17Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpev61z9uz/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.25381s\n",
            "INFO:tensorflow:Finished evaluation at 2020-10-10-18:23:18\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.93333334, average_loss = 0.42821681, global_step = 5000, loss = 0.42821681\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpev61z9uz/model.ckpt-5000\n",
            "\n",
            "Test set accuracy: 0.933\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnPMP5EHph17"
      },
      "source": [
        "Unlike the call to the `train` method, the `steps`\n",
        "argument wasn't passed to evaluate. The `input_fn` for eval only yields a single\n",
        "[epoch](https://developers.google.com/machine-learning/glossary/#epoch) of data.\n",
        "\n",
        "\n",
        "The `eval_result` dictionary also contains the `average_loss` (mean loss per sample), the `loss` (mean loss per mini-batch) and the value of the estimator's `global_step` (the number of training iterations it underwent).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur624ibpp52X"
      },
      "source": [
        "### Making predictions (inferring) from the trained model\n",
        "\n",
        "There's now a trained model that produces good evaluation results.\n",
        "The trained model can be used to predict the species of a flower\n",
        "based on some unlabeled measurements. As with training and evaluation, you make\n",
        "predictions using a single function call:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wltc0jpgng38"
      },
      "source": [
        "# Generating predictions from the model\n",
        "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
        "predict_x = {\n",
        "    'SepalLength': [5.1, 5.9, 6.9],\n",
        "    'SepalWidth': [3.3, 3.0, 3.1],\n",
        "    'PetalLength': [1.7, 4.2, 5.4],\n",
        "    'PetalWidth': [0.5, 1.5, 2.1],\n",
        "}\n",
        "\n",
        "def input_fn(features, batch_size=256):\n",
        "    \"\"\"An input function for prediction.\"\"\"\n",
        "    # Converting the inputs to a Dataset without labels.\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "predictions = classifier.predict(\n",
        "    input_fn=lambda: input_fn(predict_x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsETKQo0rHvi"
      },
      "source": [
        "The `predict` method returns a Python iterable, yielding a dictionary of\n",
        "prediction results for each example. The following code prints a few\n",
        "predictions and their probabilities:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efm4mLzkrCxp",
        "outputId": "7854072d-7519-421c-8ad5-d2c83efb37b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "for pred_dict, expec in zip(predictions, expected):\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
        "        SPECIES[class_id], 100 * probability, expec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpev61z9uz/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Prediction is \"Setosa\" (73.8%), expected \"Setosa\"\n",
            "Prediction is \"Versicolor\" (60.5%), expected \"Versicolor\"\n",
            "Prediction is \"Virginica\" (68.8%), expected \"Virginica\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}