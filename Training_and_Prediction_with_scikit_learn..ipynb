{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_and_Prediction_with_scikit_learn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGGtIWWKh16l"
      },
      "source": [
        "## Confidentiality\n",
        "\n",
        "This notebook is downloaded from Gcp AI hub and is for demonstrational purposes only.\n",
        "\n",
        "Please do not copy or distribute this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxbK17FXklrr"
      },
      "source": [
        "## Introduction\n",
        "This notebook uses the [Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Census+Income) to demonstrate how to train a model and generate local predictions.\n",
        "\n",
        "\n",
        "##  The data\n",
        "The [Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Census+Income) that this sample\n",
        "uses for training is provided by the [UC Irvine Machine Learning\n",
        "Repository](https://archive.ics.uci.edu/ml/datasets/). Google has hosted the data on a public GCS bucket `gs://cloud-samples-data/ml-engine/sklearn/census_data/` and also hosted in the UC Irvine dataset repository.\n",
        "\n",
        " * Training file is `adult.data`\n",
        " * Evaluation file is `adult.test`\n",
        "\n",
        "\n",
        "### Disclaimer\n",
        "This dataset is provided by a third party. Google provides no representation,\n",
        "warranty, or other guarantees about the validity or any other aspects of this dataset.\n",
        "\n",
        "# Build your model\n",
        "\n",
        "First, the model is created (provided below). This is similar to a normal process for creating a scikit-learn model. However, there is one key difference:\n",
        "\n",
        "1. Downloading the data at the start of the file, so that the data can be accessed. \n",
        "\n",
        "The code in this file loads the data into a pandas DataFrame that can be used by scikit-learn. Then the model is fit against the training data. Lastly, sklearn's built in version of joblib is used to save the model to a file that can be uploaded to [ML Engine's prediction service](https://cloud.google.com/ml-engine/docs/scikit/getting-predictions#deploy_models_and_versions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJeDGLu-klrt",
        "outputId": "20aa5793-8346-4830-b070-b20f7bd90601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvjV12Wwklr0"
      },
      "source": [
        "Adding code to download the data (in this case, using the publicly hosted data).\n",
        "to be able to use the data when training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BauE29a2klr2",
        "outputId": "a404ab2f-dbca-49ad-90cf-c55cff2347d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Downloading the data\n",
        "! curl https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data --output adult.data\n",
        "! curl https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test --output adult.test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3881k  100 3881k    0     0  8511k      0 --:--:-- --:--:-- --:--:-- 8511k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1956k  100 1956k    0     0  5719k      0 --:--:-- --:--:-- --:--:-- 5719k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDEk7UnXklr7"
      },
      "source": [
        "# Reading in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tqKPSkXklr9"
      },
      "source": [
        "# Defining the format of the input data including unused columns (These are the columns from the census data files)\n",
        "COLUMNS = (\n",
        "    'age',\n",
        "    'workclass',\n",
        "    'fnlwgt',\n",
        "    'education',\n",
        "    'education-num',\n",
        "    'marital-status',\n",
        "    'occupation',\n",
        "    'relationship',\n",
        "    'race',\n",
        "    'sex',\n",
        "    'capital-gain',\n",
        "    'capital-loss',\n",
        "    'hours-per-week',\n",
        "    'native-country',\n",
        "    'income-level'\n",
        ")\n",
        "\n",
        "# Categorical columns are columns that need to be turned into a numerical value to be used by scikit-learn\n",
        "CATEGORICAL_COLUMNS = (\n",
        "    'workclass',\n",
        "    'education',\n",
        "    'marital-status',\n",
        "    'occupation',\n",
        "    'relationship',\n",
        "    'race',\n",
        "    'sex',\n",
        "    'native-country'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41MMaoVuklsB"
      },
      "source": [
        "Loading the training census dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdGpxLSMklsC"
      },
      "source": [
        "with open('./adult.data', 'r') as train_data:\n",
        "    raw_training_data = pd.read_csv(train_data, header=None, names=COLUMNS)\n",
        "\n",
        "# Removing the column that has to be predicted ('income-level') from the features list\n",
        "# Converting the Dataframe to a lists of lists\n",
        "train_features = raw_training_data.drop('income-level', axis=1).values.tolist()\n",
        "# Creating the training labels list, converting the Dataframe to a lists of lists\n",
        "train_labels = (raw_training_data['income-level'] == ' >50K').values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwCuyIpSklsG"
      },
      "source": [
        "Loading the test census dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyqn-CBPklsI"
      },
      "source": [
        "with open('./adult.test', 'r') as test_data:\n",
        "    raw_testing_data = pd.read_csv(test_data, names=COLUMNS, skiprows=1)\n",
        "# Removing the column that has to be predicted ('income-level') from the features list\n",
        "# Converting the Dataframe to a lists of lists\n",
        "test_features = raw_testing_data.drop('income-level', axis=1).values.tolist()\n",
        "# Creating the training labels list, converting the Dataframe to a lists of lists\n",
        "test_labels = (raw_testing_data['income-level'] == ' >50K.').values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkBg0WelklsM"
      },
      "source": [
        "This is the model code. Below is an example model using the census dataset.\n",
        "Since the census data set has categorical features, the numerical values have to be converted. A list of pipelines is used to convert each\n",
        "categorical column and then using FeatureUnion to combine them before calling the RandomForestClassifier.\n",
        "\n",
        "Each categorical column needs to be extracted individually and converted to a numerical value.\n",
        "To do this, each categorical column a pipeline is used that extracts one feature column via\n",
        " `SelectKBest(k=1) and a LabelBinarizer()` to convert the categorical value to a numerical one.\n",
        "A scores array (created below) selects and extracts the feature column. The scores array is\n",
        "created by iterating over the COLUMNS and checking if it is a CATEGORICAL_COLUMN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjoJTK9tklsO"
      },
      "source": [
        "categorical_pipelines = []\n",
        "\n",
        "for i, col in enumerate(COLUMNS[:-1]):\n",
        "    if col in CATEGORICAL_COLUMNS:\n",
        "        # Create a scores array to get the individual categorical column.\n",
        "        # Example:\n",
        "        #  data = [39, 'State-gov', 77516, 'Bachelors', 13, 'Never-married', 'Adm-clerical', \n",
        "        #         'Not-in-family', 'White', 'Male', 2174, 0, 40, 'United-States']\n",
        "        #  scores = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "        #\n",
        "        # Returns: [['State-gov']]\n",
        "        # Build the scores array\n",
        "        scores = [0] * len(COLUMNS[:-1])\n",
        "        # This column is the categorical column you want to extract.\n",
        "        scores[i] = 1\n",
        "        skb = SelectKBest(k=1)\n",
        "        skb.scores_ = scores\n",
        "        # Convert the categorical column to a numerical value\n",
        "        lbn = LabelBinarizer()\n",
        "        r = skb.transform(train_features)\n",
        "        lbn.fit(r)\n",
        "        # Create the pipeline to extract the categorical feature\n",
        "        categorical_pipelines.append(\n",
        "            ('categorical-{}'.format(i), Pipeline([\n",
        "                ('SKB-{}'.format(i), skb),\n",
        "                ('LBN-{}'.format(i), lbn)])))\n",
        "\n",
        "# Create pipeline to extract the numerical features\n",
        "skb = SelectKBest(k=6)\n",
        "# From COLUMNS use the features that are numerical\n",
        "skb.scores_ = [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
        "categorical_pipelines.append(('numerical', skb))\n",
        "\n",
        "# Combine all the features using FeatureUnion\n",
        "preprocess = FeatureUnion(categorical_pipelines)\n",
        "\n",
        "# Create the classifier\n",
        "classifier = RandomForestClassifier()\n",
        "\n",
        "# Transform the features and fit them to the classifier\n",
        "classifier.fit(preprocess.transform(train_features), train_labels)\n",
        "\n",
        "# Create the overall model as a single pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('union', preprocess),\n",
        "    ('classifier', classifier)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-myiB9ODklsS"
      },
      "source": [
        "Export the model to a file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pomf4DaklsT",
        "outputId": "f465367a-9537-4fd2-bb2a-fde0a03690ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = 'model.joblib'\n",
        "joblib.dump(pipeline, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR7MrOxCklsX",
        "outputId": "d877f15c-13b5-4578-95f4-24af289e9bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls -al model.joblib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 81903458 Sep 27 18:07 model.joblib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A1qkVtxklsa"
      },
      "source": [
        "## Predictions\n",
        "Selecting one person that makes <=50K and one that makes >50K to test the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7KOnIcXklsb",
        "outputId": "90842ab6-0415-42a9-c54a-874b890f6ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "print('Show a person that makes <=50K:')\n",
        "print('\\tFeatures: {0} --> Label: {1}\\n'.format(test_features[0], test_labels[0]))\n",
        "\n",
        "with open('less_than_50K.json', 'w') as outfile:\n",
        "  json.dump(test_features[0], outfile)\n",
        "\n",
        "print('Show a person that makes >50K:')\n",
        "print('\\tFeatures: {0} --> Label: {1}'.format(test_features[3], test_labels[3]))\n",
        "\n",
        "with open('more_than_50K.json', 'w') as outfile:\n",
        "  json.dump(test_features[3], outfile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Show a person that makes <=50K:\n",
            "\tFeatures: [25, ' Private', 226802, ' 11th', 7, ' Never-married', ' Machine-op-inspct', ' Own-child', ' Black', ' Male', 0, 0, 40, ' United-States'] --> Label: False\n",
            "\n",
            "Show a person that makes >50K:\n",
            "\tFeatures: [44, ' Private', 160323, ' Some-college', 10, ' Married-civ-spouse', ' Machine-op-inspct', ' Husband', ' Black', ' Male', 7688, 0, 40, ' United-States'] --> Label: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZoSdNinklse"
      },
      "source": [
        "## Use Python to make local predictions\n",
        "Test the model with the entire test set and print out some of the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9_cLER2klse"
      },
      "source": [
        "local_results = pipeline.predict(test_features)\n",
        "local = pd.Series(local_results, name='local')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5olpIPdklsh",
        "outputId": "bb1b2ad2-dc0e-4e28-db4d-ed96947bf343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "local[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    False\n",
              "1    False\n",
              "2     True\n",
              "3     True\n",
              "4    False\n",
              "5    False\n",
              "6    False\n",
              "7     True\n",
              "8    False\n",
              "9    False\n",
              "Name: local, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPlHv4nUklsj",
        "outputId": "ca67d6b0-6e91-4693-814e-230cf50b9c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Print the first 10 responses\n",
        "for i, response in enumerate(local[:10]):\n",
        "    print('Prediction: {}\\tLabel: {}'.format(response, test_labels[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: False\tLabel: False\n",
            "Prediction: False\tLabel: False\n",
            "Prediction: True\tLabel: True\n",
            "Prediction: True\tLabel: True\n",
            "Prediction: False\tLabel: False\n",
            "Prediction: False\tLabel: False\n",
            "Prediction: False\tLabel: False\n",
            "Prediction: True\tLabel: True\n",
            "Prediction: False\tLabel: False\n",
            "Prediction: False\tLabel: False\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}