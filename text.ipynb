{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6DAJDkQ7yMA"
      },
      "source": [
        "## Confidentiality\n",
        "\n",
        "This notebook is downloaded from Tensorflow and is for demonstrational purposes only.\n",
        "\n",
        "Please do not copy or distribute this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUtoed20cRJJ"
      },
      "source": [
        "# Loading text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWeQAo0Ec_BL"
      },
      "source": [
        "Here's described how to use `tf.data.TextLineDataset` to load examples from text files. `TextLineDataset` is designed to create a dataset from a text file, in which each example is a line of text from the original file. This is potentially useful for any text data that is primarily line-based (for example, management reports or error logs).\n",
        "\n",
        "Here, three different English translations are used of the same text. A model is trained to identify the translator given a single line of text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgZ9gjmPfSnK"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:31.145068Z",
          "iopub.status.busy": "2020-09-11T03:31:31.144393Z",
          "iopub.status.idle": "2020-09-11T03:31:34.039735Z",
          "shell.execute_reply": "2020-09-11T03:31:34.039214Z"
        },
        "id": "v8sAMTYv5TAr",
        "outputId": "4045ae3c-2a44-4541-ace6-6ea608fa2349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -q tfds-nightly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.6MB 3.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:34.043815Z",
          "iopub.status.busy": "2020-09-11T03:31:34.043261Z",
          "iopub.status.idle": "2020-09-11T03:31:40.063993Z",
          "shell.execute_reply": "2020-09-11T03:31:40.063425Z"
        },
        "id": "baYFZMW_bJHh"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import json, math, os, sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWVWjyIkffau"
      },
      "source": [
        "The texts of the three translations are by:\n",
        "\n",
        " - [William Cowper](https://en.wikipedia.org/wiki/William_Cowper) — [text](https://storage.googleapis.com/download.tensorflow.org/data/illiad/cowper.txt)\n",
        "\n",
        " - [Edward, Earl of Derby](https://en.wikipedia.org/wiki/Edward_Smith-Stanley,_14th_Earl_of_Derby) — [text](https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt)\n",
        "\n",
        "- [Samuel Butler](https://en.wikipedia.org/wiki/Samuel_Butler_%28novelist%29) — [text](https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt)\n",
        "\n",
        "The text files have undergone some typical preprocessing tasks, mostly removing stuff — document header and footer, line numbers, chapter titles. Downloading these preprocessed files locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:40.070543Z",
          "iopub.status.busy": "2020-09-11T03:31:40.069925Z",
          "iopub.status.idle": "2020-09-11T03:31:41.796577Z",
          "shell.execute_reply": "2020-09-11T03:31:41.796988Z"
        },
        "id": "4YlKQthEYlFw",
        "outputId": "a7f94b1c-a2db-4aa6-b4f1-33f8f05ee2df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "DIRECTORY_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
        "FILE_NAMES = ['cowper.txt', 'derby.txt', 'butler.txt']\n",
        "\n",
        "for name in FILE_NAMES:\n",
        "  text_dir = tf.keras.utils.get_file(name, origin=DIRECTORY_URL+name)\n",
        "  \n",
        "parent_dir = os.path.dirname(text_dir)\n",
        "\n",
        "parent_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/cowper.txt\n",
            "819200/815980 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt\n",
            "811008/809730 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt\n",
            "811008/807992 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3sDy6nuXoNp"
      },
      "source": [
        "## Loading text into datasets\n",
        "\n",
        "Iterating through the files, loading each one into its own dataset.\n",
        "\n",
        "Each example needs to be individually labeled, so using `tf.data.Dataset.map` to apply a labeler function to each one. This will iterate over every example in the dataset, returning (`example, label`) pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:42.630226Z",
          "iopub.status.busy": "2020-09-11T03:31:41.846429Z",
          "iopub.status.idle": "2020-09-11T03:31:42.730258Z",
          "shell.execute_reply": "2020-09-11T03:31:42.730754Z"
        },
        "id": "K0BjCOpOh7Ch"
      },
      "source": [
        "def labeler(example, index):\n",
        "  return example, tf.cast(index, tf.int64)  \n",
        "\n",
        "labeled_data_sets = []\n",
        "\n",
        "for i, file_name in enumerate(FILE_NAMES):\n",
        "  lines_dataset = tf.data.TextLineDataset(os.path.join(parent_dir, file_name))\n",
        "  labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\n",
        "  labeled_data_sets.append(labeled_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8PHK5J_cXE5"
      },
      "source": [
        "Combining these labeled datasets into a single dataset, and shuffling it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:42.735363Z",
          "iopub.status.busy": "2020-09-11T03:31:42.734672Z",
          "iopub.status.idle": "2020-09-11T03:31:42.738974Z",
          "shell.execute_reply": "2020-09-11T03:31:42.738349Z"
        },
        "id": "6jAeYkTIi9-2"
      },
      "source": [
        "BUFFER_SIZE = 50000\n",
        "BATCH_SIZE = 64\n",
        "TAKE_SIZE = 5000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:42.747189Z",
          "iopub.status.busy": "2020-09-11T03:31:42.746529Z",
          "iopub.status.idle": "2020-09-11T03:31:42.750680Z",
          "shell.execute_reply": "2020-09-11T03:31:42.750028Z"
        },
        "id": "Qd544E-Sh63L"
      },
      "source": [
        "all_labeled_data = labeled_data_sets[0]\n",
        "for labeled_dataset in labeled_data_sets[1:]:\n",
        "  all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n",
        "  \n",
        "all_labeled_data = all_labeled_data.shuffle(\n",
        "    BUFFER_SIZE, reshuffle_each_iteration=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4JEHrJXeG5k"
      },
      "source": [
        "You can use `tf.data.Dataset.take` and `print` to see what the `(example, label)` pairs look like. The `numpy` property shows each Tensor's value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:42.755313Z",
          "iopub.status.busy": "2020-09-11T03:31:42.754618Z",
          "iopub.status.idle": "2020-09-11T03:31:43.987707Z",
          "shell.execute_reply": "2020-09-11T03:31:43.987232Z"
        },
        "id": "gywKlN0xh6u5",
        "outputId": "565f80ac-0027-455e-8a88-e15ff360ccae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "for ex in all_labeled_data.take(5):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'Of Ilium and his host shall perish all.'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'sat apart in his all-glorious majesty, looking down upon the city of'>, <tf.Tensor: shape=(), dtype=int64, numpy=2>)\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b\"Down from his chariot with his arms he leap'd,\">, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b\"Whereon his incense-honour'd altar stood:\">, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b\"Of Peleus' godlike son, that thy own ship\">, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rrpU2_sfDh0"
      },
      "source": [
        "## Encoding text lines as numbers\n",
        "\n",
        "Machine learning models work on numbers, not words, so the string values need to be converted into lists of numbers. To do that, map each unique word to a unique integer.\n",
        "\n",
        "### Building vocabulary\n",
        "\n",
        "First, building a vocabulary by tokenizing the text into a collection of individual unique words. There are a few ways to do this in both TensorFlow and Python:\n",
        "\n",
        "1. Iterate over each example's `numpy` value.\n",
        "2. Use `tfds.deprecated.text.Tokenizer` to split it into tokens.\n",
        "3. Collect these tokens into a Python set, to remove duplicates.\n",
        "4. Get the size of the vocabulary for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:43.998168Z",
          "iopub.status.busy": "2020-09-11T03:31:43.997537Z",
          "iopub.status.idle": "2020-09-11T03:31:49.700158Z",
          "shell.execute_reply": "2020-09-11T03:31:49.700595Z"
        },
        "id": "YkHtbGnDh6mg",
        "outputId": "a5d1da3d-b79c-44c2-d609-2e1b6bb49b30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = tfds.deprecated.text.Tokenizer()\n",
        "\n",
        "vocabulary_set = set()\n",
        "for text_tensor, _ in all_labeled_data:\n",
        "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
        "  vocabulary_set.update(some_tokens)\n",
        "\n",
        "vocab_size = len(vocabulary_set)\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W35VJqAh9zs"
      },
      "source": [
        "### Encoding examples\n",
        "\n",
        "Creating an encoder by passing the `vocabulary_set` to `tfds.deprecated.text.TokenTextEncoder`. The encoder's `encode` method takes in a string of text and returns a list of integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:49.727204Z",
          "iopub.status.busy": "2020-09-11T03:31:49.726568Z",
          "iopub.status.idle": "2020-09-11T03:31:49.728401Z",
          "shell.execute_reply": "2020-09-11T03:31:49.728925Z"
        },
        "id": "gkxJIVAth6j0"
      },
      "source": [
        "encoder = tfds.deprecated.text.TokenTextEncoder(vocabulary_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6S5Qyabi-vo"
      },
      "source": [
        "Trying this on a single line to see what the output looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:49.733072Z",
          "iopub.status.busy": "2020-09-11T03:31:49.732424Z",
          "iopub.status.idle": "2020-09-11T03:31:50.891453Z",
          "shell.execute_reply": "2020-09-11T03:31:50.891015Z"
        },
        "id": "jgxPZaxUuTbk",
        "outputId": "f2c079a4-dd79-4c30-96d4-86db5578094b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_text = next(iter(all_labeled_data))[0].numpy()\n",
        "print(example_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Of Ilium and his host shall perish all.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:50.895699Z",
          "iopub.status.busy": "2020-09-11T03:31:50.894968Z",
          "iopub.status.idle": "2020-09-11T03:31:50.897874Z",
          "shell.execute_reply": "2020-09-11T03:31:50.897387Z"
        },
        "id": "XoVpKR3qj5yb",
        "outputId": "563f5c55-4656-442e-b34f-8079c580b696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoded_example = encoder.encode(example_text)\n",
        "print(encoded_example)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8488, 11525, 14014, 711, 1682, 11795, 13485, 9832]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9qHM0v8k_Mg"
      },
      "source": [
        "Running the encoder on the dataset by wrapping it in `tf.py_function` and  passing that to the dataset's `map` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:50.901563Z",
          "iopub.status.busy": "2020-09-11T03:31:50.900981Z",
          "iopub.status.idle": "2020-09-11T03:31:50.903238Z",
          "shell.execute_reply": "2020-09-11T03:31:50.902812Z"
        },
        "id": "HcIQ7LOTh6eT"
      },
      "source": [
        "def encode(text_tensor, label):\n",
        "  encoded_text = encoder.encode(text_tensor.numpy())\n",
        "  return encoded_text, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eES_Z1ia-Om-"
      },
      "source": [
        "Using `Dataset.map` to apply this function to each element of the dataset.  `Dataset.map` runs in graph mode.\n",
        "\n",
        "* Graph tensors do not have a value. \n",
        "* In graph mode you can only use TensorFlow Ops and functions. \n",
        "\n",
        "Wrapping it in a `tf.py_function`. The `tf.py_function` will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:50.908746Z",
          "iopub.status.busy": "2020-09-11T03:31:50.908157Z",
          "iopub.status.idle": "2020-09-11T03:31:50.950835Z",
          "shell.execute_reply": "2020-09-11T03:31:50.950411Z"
        },
        "id": "KmQVsAgJ-RM0"
      },
      "source": [
        "def encode_map_fn(text, label):\n",
        "  # py_func doesn't set the shape of the returned tensors.\n",
        "  encoded_text, label = tf.py_function(encode, \n",
        "                                       inp=[text, label], \n",
        "                                       Tout=(tf.int64, tf.int64))\n",
        "\n",
        "  # `tf.data.Datasets` work best if all components have a shape set\n",
        "  #  so setting the shapes manually: \n",
        "  encoded_text.set_shape([None])\n",
        "  label.set_shape([])\n",
        "\n",
        "  return encoded_text, label\n",
        "\n",
        "\n",
        "all_encoded_data = all_labeled_data.map(encode_map_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YZToSXSm0qr"
      },
      "source": [
        "## Splitting the dataset into test and train batches\n",
        "\n",
        "Using `tf.data.Dataset.take` and `tf.data.Dataset.skip` to create a small test dataset and a larger training set.\n",
        "\n",
        "Before being passed into the model, the datasets need to be batched. Typically, the examples inside of a batch need to be the same size and shape. But, the examples in these datasets are not all the same size — each line of text had a different number of words. So using `tf.data.Dataset.padded_batch` (instead of `batch`) to pad the examples to the same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:50.954911Z",
          "iopub.status.busy": "2020-09-11T03:31:50.954351Z",
          "iopub.status.idle": "2020-09-11T03:31:50.959263Z",
          "shell.execute_reply": "2020-09-11T03:31:50.959619Z"
        },
        "id": "r-rmbijQh6bf"
      },
      "source": [
        "train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n",
        "train_data = train_data.padded_batch(BATCH_SIZE)\n",
        "\n",
        "test_data = all_encoded_data.take(TAKE_SIZE)\n",
        "test_data = test_data.padded_batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdz7SVwmqi1l"
      },
      "source": [
        "Now, `test_data` and `train_data` are not collections of (`example, label`) pairs, but collections of batches. Each batch is a pair of (*many examples*, *many labels*) represented as arrays.\n",
        "\n",
        "To illustrate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:50.963098Z",
          "iopub.status.busy": "2020-09-11T03:31:50.962553Z",
          "iopub.status.idle": "2020-09-11T03:31:52.388377Z",
          "shell.execute_reply": "2020-09-11T03:31:52.388759Z"
        },
        "id": "kMslWfuwoqpB",
        "outputId": "4f1637b6-b171-4462-882d-500ccdedfaee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "sample_text, sample_labels = next(iter(test_data))\n",
        "\n",
        "sample_text[0], sample_labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(15,), dtype=int64, numpy=\n",
              " array([ 8488, 11525, 14014,   711,  1682, 11795, 13485,  9832,     0,\n",
              "            0,     0,     0,     0,     0,     0])>,\n",
              " <tf.Tensor: shape=(), dtype=int64, numpy=0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI4I6_Sa0vWu"
      },
      "source": [
        "Since there's introduced a new token encoding (the zero used for padding), the vocabulary size has increased by one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:52.392400Z",
          "iopub.status.busy": "2020-09-11T03:31:52.391784Z",
          "iopub.status.idle": "2020-09-11T03:31:52.394155Z",
          "shell.execute_reply": "2020-09-11T03:31:52.393713Z"
        },
        "id": "IlD1Lli91vuc"
      },
      "source": [
        "vocab_size += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8SUhGFNsmRi"
      },
      "source": [
        "## Building the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:52.397708Z",
          "iopub.status.busy": "2020-09-11T03:31:52.397127Z",
          "iopub.status.idle": "2020-09-11T03:31:52.406816Z",
          "shell.execute_reply": "2020-09-11T03:31:52.406351Z"
        },
        "id": "QJgI1pow2YR9"
      },
      "source": [
        "model = tf.keras.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi0iiKLTKdoF"
      },
      "source": [
        "The first layer converts integer representations to dense vector embeddings. See the [word embeddings tutorial](../text/word_embeddings.ipynb) or more details. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:52.415810Z",
          "iopub.status.busy": "2020-09-11T03:31:52.414973Z",
          "iopub.status.idle": "2020-09-11T03:31:52.426910Z",
          "shell.execute_reply": "2020-09-11T03:31:52.427363Z"
        },
        "id": "DR6-ctbY638P"
      },
      "source": [
        "model.add(tf.keras.layers.Embedding(vocab_size, 64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8OJOPohKh1q"
      },
      "source": [
        "The next layer is a [Long Short-Term Memory](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) layer, which lets the model understand words in their context with other words. A bidirectional wrapper on the LSTM helps it to learn about the datapoints in relationship to the datapoints that came before it and after it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:52.449865Z",
          "iopub.status.busy": "2020-09-11T03:31:52.449273Z",
          "iopub.status.idle": "2020-09-11T03:31:52.802749Z",
          "shell.execute_reply": "2020-09-11T03:31:52.802210Z"
        },
        "id": "x6rnq6DN_WUs"
      },
      "source": [
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdffbMr5LF1g"
      },
      "source": [
        "Finally there's a series of one or more densely connected layers, with the last one being the output layer. The output layer produces a probability for all the labels. The one with the highest probability is the models prediction of an example's label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:52.808552Z",
          "iopub.status.busy": "2020-09-11T03:31:52.807866Z",
          "iopub.status.idle": "2020-09-11T03:31:52.826717Z",
          "shell.execute_reply": "2020-09-11T03:31:52.827112Z"
        },
        "id": "QTEaNSnLCsv5"
      },
      "source": [
        "# One or more dense layers.\n",
        "# Editing the list in the `for` line to experiment with layer sizes.\n",
        "for units in [64, 64]:\n",
        "  model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
        "\n",
        "# Output layer. The first argument is the number of labels.\n",
        "model.add(tf.keras.layers.Dense(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLHPU8q5DLi_"
      },
      "source": [
        "Finally, compiling the model. For a softmax categorization model, using `sparse_categorical_crossentropy` as the loss function. You can try other optimizers, but `adam` is very common."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:52.838295Z",
          "iopub.status.busy": "2020-09-11T03:31:52.837705Z",
          "iopub.status.idle": "2020-09-11T03:31:52.845557Z",
          "shell.execute_reply": "2020-09-11T03:31:52.845916Z"
        },
        "id": "pkTBUVO4h6Y5"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM-HLo5NDhql"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "This model running on this data produces decent results (about 83%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:31:52.850237Z",
          "iopub.status.busy": "2020-09-11T03:31:52.849622Z",
          "iopub.status.idle": "2020-09-11T03:32:56.441496Z",
          "shell.execute_reply": "2020-09-11T03:32:56.441057Z"
        },
        "id": "aLtO33tNh6V8",
        "outputId": "db404004-3e92-4467-f2b5-b53db4355fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "model.fit(train_data, epochs=3, validation_data=test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "697/697 [==============================] - 27s 38ms/step - loss: 0.4976 - accuracy: 0.7629 - val_loss: 0.3920 - val_accuracy: 0.8200\n",
            "Epoch 2/3\n",
            "697/697 [==============================] - 26s 37ms/step - loss: 0.2916 - accuracy: 0.8739 - val_loss: 0.3695 - val_accuracy: 0.8320\n",
            "Epoch 3/3\n",
            "697/697 [==============================] - 26s 37ms/step - loss: 0.2187 - accuracy: 0.9050 - val_loss: 0.3940 - val_accuracy: 0.8322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1de01cebe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-09-11T03:32:56.445438Z",
          "iopub.status.busy": "2020-09-11T03:32:56.444879Z",
          "iopub.status.idle": "2020-09-11T03:32:58.971638Z",
          "shell.execute_reply": "2020-09-11T03:32:58.971164Z"
        },
        "id": "KTPCYf_Jh6TH",
        "outputId": "9de584d5-204c-4954-db33-cd6312ac467d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "eval_loss, eval_acc = model.evaluate(test_data)\n",
        "\n",
        "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 2s 25ms/step - loss: 0.3940 - accuracy: 0.8322\n",
            "\n",
            "Eval loss: 0.394, Eval accuracy: 0.832\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}